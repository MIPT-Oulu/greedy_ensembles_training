seed: 42
n_gpus: 1
number_of_nodes: 1
snapshot_dir: workdir/${experiment_cat}_output_${seed}_${ensemble.ens_size}/${now:%Y-%m-%d}/${now:%H-%M-%S}
train:
  distributed: false
  num_epochs: 300
  init_from: ~
  break_every_iter: false
logging:
  formatters:
    simple:
      format: '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'
  handlers:
    console:
      class: logging.StreamHandler
      formatter: simple
      stream: ext://sys.stdout
    file:
      class: logging.FileHandler
      filename: ${snapshot_dir}/pipeline.log
      formatter: simple
  root:
    handlers:
      - console
      - file
    level: INFO
  version: 1
data:
  std_mult_fnorm: 5
  num_classes: 10
  dataset: cifar${data.num_classes}
  dataset_cls: gde.data.dataset.DataFrameImageDataset
  dataloader_cls: gde.data.dataset.FastDataLoader
  num_workers: 4
  batch_size: 128
  mean: ~
  std: ~
  divide_batch_per_n_gpus: true
  val_amount: 0.1
  augs:
    train:
      stream:
        transforms:
          - flip:
              axis: 1
              p: 0.5
          - pad:
              pad_to: 36
              padding: r
          - crop:
              crop_to: 32
              crop_mode: r
    val: ~
checkpointer:
  keep_old: false
ensemble:
  ens_size: 11
  greedy: false
  diversity_lambda: 0.0001
optimizer:
  scheduler:
    warmup_for: 0
    warmup_from: ~
criterion:
  cls: torch.nn.CrossEntropyLoss
  params: ~
defaults:
  - experiment: cifar_resnet